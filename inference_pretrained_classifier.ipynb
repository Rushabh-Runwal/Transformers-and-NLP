{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inference with a Pretrained Classifier using Keras NLP"
      ],
      "metadata": {
        "id": "0OOH5RIAClIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates how to use pretrained models for text classification tasks"
      ],
      "metadata": {
        "id": "gGStHVbTxM9j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWNiidUICeH3",
        "outputId": "25c8ab7a-a530-40c8-8d53-70077b4c2c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "Keras NLP version: 0.18.1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import keras_nlp\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Keras NLP version:\", keras_nlp.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's use a pretrained BERT classifier for sentiment analysis\n",
        "# We'll use the BERT classifier pretrained on IMDB reviews\n",
        "\n",
        "# Load the pretrained model\n",
        "model = keras_nlp.models.BertClassifier.from_preset(\n",
        "    \"bert_base_en_uncased\",     # <-- Corrected: Use the base model preset\n",
        "    num_classes=2              # Specify number of classes for the head\n",
        ")"
      ],
      "metadata": {
        "id": "iVixyQGkxWw-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Let's try inference with some example reviews\n",
        "positive_review = \"This movie was fantastic! I really enjoyed the plot and the acting was superb.\"\n",
        "negative_review = \"What a waste of time. Poor acting, terrible script, and boring storyline.\"\n",
        "mixed_review = \"The movie had good special effects but the story was somewhat confusing.\""
      ],
      "metadata": {
        "id": "D8NGThd2xbKA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Let's create a batch of example texts\n",
        "example_texts = [\n",
        "    positive_review,\n",
        "    negative_review,\n",
        "    mixed_review,\n",
        "    \"I fell asleep halfway through the movie.\",\n",
        "    \"The characters were well-developed and the dialogue was engaging.\",\n",
        "    \"I can't believe I paid to watch this. It was terrible.\",\n",
        "    \"One of the best films I've seen this year!\",\n",
        "    \"It was okay, nothing special but not terrible either.\"\n",
        "]"
      ],
      "metadata": {
        "id": "tB_6fW7kxdWG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print review classification with timing\n",
        "print(\"\\n===== Review Classification =====\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Get raw predictions\n",
        "predictions = model.predict(example_texts)\n",
        "end_time = time.time()\n",
        "\n",
        "# Convert to predicted class (0 = negative, 1 = positive)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Print results\n",
        "for i, text in enumerate(example_texts):\n",
        "    sentiment = \"Positive\" if predicted_classes[i] == 1 else \"Negative\"\n",
        "    confidence = predictions[i][predicted_classes[i]]\n",
        "    print(f\"\\nReview: {text}\")\n",
        "    print(f\"Prediction: {sentiment} (confidence: {confidence:.4f})\")\n",
        "    print(f\"Full logits: {predictions[i]}\")\n",
        "\n",
        "print(f\"\\nTime taken for {len(example_texts)} predictions: {end_time - start_time:.4f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__UPjbazxfQH",
        "outputId": "7021428d-8996-47bc-c380-089d2d3322e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Review Classification =====\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
            "\n",
            "Review: This movie was fantastic! I really enjoyed the plot and the acting was superb.\n",
            "Prediction: Negative (confidence: 0.1004)\n",
            "Full logits: [ 0.10040806 -0.51283854]\n",
            "\n",
            "Review: What a waste of time. Poor acting, terrible script, and boring storyline.\n",
            "Prediction: Negative (confidence: 0.1298)\n",
            "Full logits: [ 0.12977979 -0.4779127 ]\n",
            "\n",
            "Review: The movie had good special effects but the story was somewhat confusing.\n",
            "Prediction: Negative (confidence: 0.0717)\n",
            "Full logits: [ 0.07173215 -0.5124194 ]\n",
            "\n",
            "Review: I fell asleep halfway through the movie.\n",
            "Prediction: Negative (confidence: 0.0976)\n",
            "Full logits: [ 0.09757428 -0.46804893]\n",
            "\n",
            "Review: The characters were well-developed and the dialogue was engaging.\n",
            "Prediction: Negative (confidence: 0.0865)\n",
            "Full logits: [ 0.08649753 -0.49885035]\n",
            "\n",
            "Review: I can't believe I paid to watch this. It was terrible.\n",
            "Prediction: Negative (confidence: 0.0791)\n",
            "Full logits: [ 0.07907256 -0.46644655]\n",
            "\n",
            "Review: One of the best films I've seen this year!\n",
            "Prediction: Negative (confidence: 0.0779)\n",
            "Full logits: [ 0.07786351 -0.5424526 ]\n",
            "\n",
            "Review: It was okay, nothing special but not terrible either.\n",
            "Prediction: Negative (confidence: 0.0350)\n",
            "Full logits: [ 0.03502554 -0.47055513]\n",
            "\n",
            "Time taken for 8 predictions: 7.7070 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Let's demonstrate how we can process a single input for real-time applications\n",
        "print(\"\\n===== Single Input Processing =====\")\n",
        "single_input = \"I would recommend this movie to all my friends!\"\n",
        "\n",
        "start_time = time.time()\n",
        "prediction = model.predict([single_input])\n",
        "end_time = time.time()\n",
        "\n",
        "predicted_class = np.argmax(prediction[0])\n",
        "sentiment = \"Positive\" if predicted_class == 1 else \"Negative\"\n",
        "\n",
        "print(f\"Review: {single_input}\")\n",
        "print(f\"Prediction: {sentiment} (confidence: {prediction[0][predicted_class]:.4f})\")\n",
        "print(f\"Time taken: {end_time - start_time:.4f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKAvgeqTxki-",
        "outputId": "1eaf4cb4-9ee7-44f6-c90b-6d7f61a53f0f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Single Input Processing =====\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
            "Review: I would recommend this movie to all my friends!\n",
            "Prediction: Negative (confidence: 0.0509)\n",
            "Time taken: 6.2948 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Demonstration of how to handle longer text by breaking it into chunks\n",
        "print(\"\\n===== Processing Longer Text =====\")\n",
        "long_review = \"\"\"\n",
        "This movie was a rollercoaster of emotions. The beginning was slow and I almost turned it off,\n",
        "but I'm glad I didn't because the middle part picked up significantly. The character development\n",
        "was incredible and by the end I was fully invested in their journey. The cinematography was\n",
        "breathtaking and the score complemented each scene perfectly. However, some plot points were\n",
        "left unresolved which was a bit disappointing. Overall, despite its flaws, I would recommend\n",
        "watching it for the stellar performances of the main cast.\n",
        "\"\"\"\n",
        "\n",
        "# We could split long text into chunks if needed\n",
        "chunks = [long_review]  # For this example, we'll process it as one piece\n",
        "\n",
        "# Process each chunk\n",
        "chunk_predictions = []\n",
        "for chunk in chunks:\n",
        "    prediction = model.predict([chunk])[0]\n",
        "    chunk_predictions.append(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE-P_-yOxmUq",
        "outputId": "5e08fb92-df3c-41f7-dce4-40392a42db25"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Processing Longer Text =====\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Average predictions across chunks if we had multiple\n",
        "final_prediction = np.mean(chunk_predictions, axis=0)\n",
        "final_class = np.argmax(final_prediction)\n",
        "sentiment = \"Positive\" if final_class == 1 else \"Negative\"\n",
        "\n",
        "print(f\"Long Review Analysis:\")\n",
        "print(f\"Prediction: {sentiment} (confidence: {final_prediction[final_class]:.4f})\")\n",
        "print(f\"Logits: {final_prediction}\")\n",
        "\n",
        "# Let's look at how different models might perform\n",
        "print(\"\\n===== Comparing Different Pretrained Models =====\")\n",
        "# Note: In a real application, you might want to load these models and compare\n",
        "# their performance on your specific task\n",
        "\n",
        "print(\"Available BERT presets for classification:\")\n",
        "bert_presets = [p for p in keras_nlp.models.BertClassifier.presets if \"classifier\" in p or \"imdb\" in p]\n",
        "for preset in bert_presets:\n",
        "    print(f\" - {preset}\")\n",
        "\n",
        "print(\"\\nNote: You could load different models to compare their performance:\")\n",
        "print(\"model_1 = keras_nlp.models.BertClassifier.from_preset('bert_base_en_uncased_imdb')\")\n",
        "print(\"model_2 = keras_nlp.models.RobertaClassifier.from_preset('roberta_base_en_imdb')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN7wUDQ9xpIb",
        "outputId": "518b3476-63d1-47bb-ee90-487a5be8deb1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Long Review Analysis:\n",
            "Prediction: Negative (confidence: 0.1237)\n",
            "Logits: [ 0.12373428 -0.4878066 ]\n",
            "\n",
            "===== Comparing Different Pretrained Models =====\n",
            "Available BERT presets for classification:\n",
            "\n",
            "Note: You could load different models to compare their performance:\n",
            "model_1 = keras_nlp.models.BertClassifier.from_preset('bert_base_en_uncased_imdb')\n",
            "model_2 = keras_nlp.models.RobertaClassifier.from_preset('roberta_base_en_imdb')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Show how to save and load the model for future use\n",
        "print(\"\\n===== Saving and Loading Models =====\")\n",
        "# Save to temporary file for demonstration\n",
        "model_save_path = \"/tmp/bert_classifier.keras\"\n",
        "print(f\"Saving model to {model_save_path}\")\n",
        "model.save(model_save_path)\n",
        "\n",
        "print(f\"Loading model from {model_save_path}\")\n",
        "loaded_model = tf.keras.models.load_model(model_save_path)\n",
        "\n",
        "# Verify loaded model works\n",
        "test_input = \"This is a great example of how to use pretrained models.\"\n",
        "test_prediction = loaded_model.predict([test_input])\n",
        "test_class = np.argmax(test_prediction[0])\n",
        "test_sentiment = \"Positive\" if test_class == 1 else \"Negative\"\n",
        "\n",
        "print(f\"Test prediction with loaded model: {test_sentiment}\")\n",
        "print(\"\\nComplete! You've successfully used a pretrained BERT classifier for sentiment analysis.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQkbtTP9Cp6f",
        "outputId": "413e3fe0-503a-4f3a-acde-fa2967089f68"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Saving and Loading Models =====\n",
            "Saving model to /tmp/bert_classifier.keras\n",
            "Loading model from /tmp/bert_classifier.keras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "Test prediction with loaded model: Negative\n",
            "\n",
            "Complete! You've successfully used a pretrained BERT classifier for sentiment analysis.\n"
          ]
        }
      ]
    }
  ]
}